# ğŸ¬ AI Influencer: Agentic AI for YouTube Shorts

`aiinfluencer` is an agentic framework that turns thematic prompts into compelling, fully-produced YouTube Shorts. Inspired by the capabilities of LangGraph and the rise of generative storytelling, this project orchestrates multiple AI agents to interpret themes, craft stories, synthesize media, and publish video content.

## ğŸš€ Project Vision

Transform a single ideaâ€”like *â€œa stitch in time saves nineâ€*â€”into a professional-grade video short through a seamless AI-driven pipeline.

---

## ğŸ§  Architecture Overview

- **Prompt Agent** â€“ Understands the thematic prompt and extracts narrative cues.
- **Story Agent** â€“ Generates a short-form story based on the prompt.
- **Screenplay Agent** â€“ Translates story into a screenplay format.
- **Visual Agent** â€“ Uses Synthesia to generate a video using my own avatar.
- **Assembly Agent** â€“ Merges content and gets it ready for the final publication
- **Publishing Agent** â€“ Uploads finalized video to YouTube Shorts.

Each stage is powered by LangGraph for stateful, multi-agent orchestration.

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourhandle/aiinfluencer.git
cd aiinfluencer
pip install -r requirements.txt

---
Fantastic project, Aadharsh. You're essentially assembling a Hollywood production line, but the stars are LLM agents, and they don't ask for trailers or green M\&Ms. Below is a solid, scalable folder structure and a `README.md` template tailored for your project: **`aiinfluencer`**.

---

## ğŸ“ Recommended Folder Structure

```
aiinfluencer/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ settings.yaml            # Configuration for agent orchestration, API keys, etc.
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ prompts/                 # Raw or example prompts
â”‚   â”œâ”€â”€ outputs/                 # Generated content (narratives, scripts)
â”‚   â””â”€â”€ media/                   # Temp storage for videos/audio/images
â”‚
â”œâ”€â”€ aiinfluencer/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # Entry point to trigger the full pipeline
â”‚   â”œâ”€â”€ agent_orchestrator.py   # LangGraph-based agent orchestration
â”‚   â”œâ”€â”€ utils.py                 # Helper functions (e.g., file I/O, logging)
â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prompt_agent.py          # Interprets thematic prompts
â”‚   â”‚   â”œâ”€â”€ story_agent.py           # Builds the narrative
â”‚   â”‚   â”œâ”€â”€ screenplay_agent.py      # Converts story to screenplay
â”‚   â”‚   â”œâ”€â”€ tts_agent.py             # Text-to-speech generation
â”‚   â”‚   â”œâ”€â”€ visual_agent.py          # Generates visuals or text-to-video
â”‚   â”‚   â”œâ”€â”€ assembly_agent.py        # Combines A/V into final short
â”‚   â”‚   â””â”€â”€ publishing_agent.py      # Uploads video to YouTube Shorts
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_pipeline.py         # Unit tests for agent workflows
â”‚
â””â”€â”€ docs/
    â””â”€â”€ architecture.md          # Extended documentation, diagrams, etc.
```

---

## ğŸ“ `README.md`

````markdown
# ğŸ¬ aiinfluencer: Agentic AI for YouTube Shorts

`aiinfluencer` is an agentic framework that turns thematic prompts into compelling, fully-produced YouTube Shorts. Inspired by the capabilities of LangGraph and the rise of generative storytelling, this project orchestrates multiple AI agents to interpret themes, craft stories, synthesize media, and publish video content.

## ğŸš€ Project Vision

Transform a single ideaâ€”like *â€œa stitch in time saves nineâ€*â€”into a professional-grade video short through a seamless AI-driven pipeline.

---

## ğŸ§  Architecture Overview

- **Prompt Agent** â€“ Understands the thematic prompt and extracts narrative cues.
- **Story Agent** â€“ Generates a short-form story based on the prompt.
- **Screenplay Agent** â€“ Translates story into a screenplay format.
- **TTS Agent** â€“ Generates voiceovers using TTS services like ElevenLabs or Polly.
- **Visual Agent** â€“ Uses RunwayML, Pika Labs, or similar to generate matching visuals.
- **Assembly Agent** â€“ Merges audio-visual content using MoviePy/FFmpeg.
- **Publishing Agent** â€“ Uploads finalized video to YouTube Shorts.

Each stage is powered by LangGraph for stateful, multi-agent orchestration.

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/yourhandle/aiinfluencer.git
cd aiinfluencer
pip install -r requirements.txt
````

Set up your configuration in `configs/settings.yaml`.

---

## ğŸ§ª Run the Pipeline

```bash
python aiinfluencer/main.py --prompt "a stitch in time saves nine"
```

Or run tests:

```bash
pytest tests/
```

---

## ğŸ“¦ Tech Stack

* **LangGraph** â€“ Agent orchestration
* **GPT-4o** â€“ Story and screenplay generation
* **Synthesia** â€“ Visual synthesis
* **YouTube Data API** â€“ Publishing

---

## ğŸ“ˆ Scaling & Deployment

* Cloud compute for media rendering (Synthesia)
* Local storage for media assets (move to cloud in the future)
* LangSmith for agent observability and logging

---

## ğŸ§¾ License

Copyrighted work by Aadharsh Kannan. Contact aadharshkannan@gmail.com for licensing.

---

## ğŸ™ Acknowledgments

Inspired by the LangGraph ecosystem and the creative potential of AI media generation.
